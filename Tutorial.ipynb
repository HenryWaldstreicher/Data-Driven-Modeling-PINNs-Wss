{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "75216f9c-93b0-4748-a4e1-ed0f3d390da9",
   "metadata": {},
   "source": [
    "### If the below pip/conda commands don't work in the notebook paste them into your terminal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "32b51797-d508-47b2-9b2e-f40a3a76a907",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (1479180360.py, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[4], line 2\u001b[0;36m\u001b[0m\n\u001b[0;31m    pip3 install torch torchvision torchaudio\u001b[0m\n\u001b[0m         ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "## For Windows using pip\n",
    "pip3 install torch torchvision torchaudio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c3d3f665-5718-47df-8ec2-a6b26aa33191",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (419726959.py, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[5], line 2\u001b[0;36m\u001b[0m\n\u001b[0;31m    conda install pytorch torchvision torchaudio cpuonly -c pytorch\u001b[0m\n\u001b[0m          ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "### For Windows using conda\n",
    "conda install pytorch torchvision torchaudio cpuonly -c pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2163a132-e12c-4de0-8f1e-e04c013e52a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "## For mac using conda\n",
    "conda install pytorch torchvision torchaudio -c pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4f02b50-9780-49eb-bcd3-415bd2a455e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "## For mac using pip\n",
    "pip3 install torch torchvision torchaudio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "42a00f64-a5a9-4928-a4b6-f543b24f99cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: vtk in /opt/conda/lib/python3.10/site-packages (9.2.6)\n",
      "Requirement already satisfied: matplotlib>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from vtk) (3.6.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=2.0.0->vtk) (22.0)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=2.0.0->vtk) (9.2.0)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=2.0.0->vtk) (3.0.9)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=2.0.0->vtk) (0.11.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=2.0.0->vtk) (2.8.2)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=2.0.0->vtk) (1.4.4)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=2.0.0->vtk) (1.0.6)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=2.0.0->vtk) (4.38.0)\n",
      "Requirement already satisfied: numpy>=1.19 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=2.0.0->vtk) (1.23.5)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.7->matplotlib>=2.0.0->vtk) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install vtk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1e6b837e-74e4-4e7c-9fa2-65b298ba35fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import pdb\n",
    "import csv\n",
    "from torch.utils.data import DataLoader, TensorDataset,RandomSampler\n",
    "from math import exp, sqrt,pi\n",
    "import time\n",
    "import vtk\n",
    "from vtk.util import numpy_support as VN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ec8e8800-0bff-4001-b5ba-429ef3bd094b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def geo_train(device,x_in,y_in,xb,yb,ub,vb,xd,yd,ud,vd,\n",
    "             batchsize,learning_rate,epochs,path,Flag_batch,\n",
    "              Diff,rho,Flag_BC_exact,Lambda_BC,nPt,T,xb_inlet,\n",
    "              yb_inlet,ub_inlet,vb_inlet):\n",
    "    \n",
    "    if Flag_batch:\n",
    "        x = torch.Tensor(x_in).to(device)\n",
    "        y = torch.Tensor(y_in).to(device)\n",
    "    #dataset = TensorDataset(x,y)\n",
    "        xb = torch.Tensor(xb).to(device)\n",
    "        yb = torch.Tensor(yb).to(device)\n",
    "        ub = torch.Tensor(ub).to(device)\n",
    "        vb = torch.Tensor(vb).to(device)\n",
    "        xd = torch.Tensor(xd).to(device)\n",
    "        yd = torch.Tensor(yd).to(device)\n",
    "        ud = torch.Tensor(ud).to(device)\n",
    "        vd = torch.Tensor(vd).to(device)\n",
    "    #dist = torch.Tensor(dist).to(device)\n",
    "        xb_inlet = torch.Tensor(xb_inlet).to(device)\n",
    "        yb_inlet = torch.Tensor(yb_inlet).to(device)\n",
    "        ub_inlet = torch.Tensor(ub_inlet).to(device)\n",
    "        vb_inlet = torch.Tensor(vb_inlet).to(device)\n",
    "        \n",
    "    if 1: #Cuda slower in double? \n",
    "        \n",
    "        x = x.type(torch.FloatTensor)\n",
    "        y = y.type(torch.FloatTensor)\n",
    "        xb = xb.type(torch.FloatTensor)\n",
    "        yb = yb.type(torch.FloatTensor)\n",
    "        ub = ub.type(torch.FloatTensor)\n",
    "        vb = vb.type(torch.FloatTensor)\n",
    "        #dist = dist.type(torch.cuda.FloatTensor)\n",
    "        xb_inlet = xb_inlet.type(torch.FloatTensor)\n",
    "        yb_inlet = yb_inlet.type(torch.FloatTensor)\n",
    "        ub_inlet = ub_inlet.type(torch.FloatTensor)\n",
    "        vb_inlet = vb_inlet.type(torch.FloatTensor)\n",
    "        xd = xd.type(torch.FloatTensor)\n",
    "        yd = yd.type(torch.FloatTensor)\n",
    "        ud = ud.type(torch.FloatTensor)\n",
    "        vd = vd.type(torch.FloatTensor)\n",
    "\n",
    "\n",
    "    dataset = TensorDataset(x,y)\n",
    "    #dataset_bc = TensorDataset(x,y,xb,yb,ub,vb,dist)\n",
    "\n",
    "    #dataloader = DataLoader(dataset, batch_size=batchsize,shuffle=True,num_workers = 0,drop_last = False )\n",
    "    dataloader = DataLoader(dataset, batch_size=batchsize,shuffle=True,num_workers = 0, drop_last = True)\n",
    "    #dataloader_bc = DataLoader(dataset_bc, batch_size=batchsize,shuffle=True,num_workers = 0, drop_last = False) \n",
    "    if Flag_batch is False:\n",
    "        x = torch.Tensor(x_in).to(device)\n",
    "        y = torch.Tensor(y_in).to(device) \n",
    "    #t = torch.Tensor(t_in).to(device) \n",
    "    #x_test =  torch.Tensor(x_test).to(device)\n",
    "    #y_test  = torch.Tensor(y_test).to(device)  \n",
    "    h_n = 128 #Width for u,v,p\n",
    "    input_n = 2 # this is what our answer is a function of (x,y). \n",
    "    class Swish(nn.Module):\n",
    "        def __init__(self, inplace=True):\n",
    "            super(Swish, self).__init__()\n",
    "            self.inplace = inplace\n",
    "\n",
    "        def forward(self, x):\n",
    "            if self.inplace:\n",
    "                x.mul_(torch.sigmoid(x))\n",
    "                return x\n",
    "            else:\n",
    "                return x * torch.sigmoid(x)\n",
    "    class MySquared(nn.Module):\n",
    "        def __init__(self, inplace=True):\n",
    "            super(MySquared, self).__init__()\n",
    "            self.inplace = inplace\n",
    "\n",
    "        def forward(self, x):\n",
    "            return torch.square(x)\n",
    "\n",
    "    class Net2_u(nn.Module):\n",
    "\n",
    "        #The __init__ function stack the layers of the \n",
    "        #network Sequentially \n",
    "        def __init__(self):\n",
    "            super(Net2_u, self).__init__()\n",
    "            self.main = nn.Sequential(\n",
    "                nn.Linear(input_n,h_n),\n",
    "                #nn.Tanh(),\n",
    "                #nn.Sigmoid(),\n",
    "                #nn.BatchNorm1d(h_n),\n",
    "                Swish(),\n",
    "                nn.Linear(h_n,h_n),\n",
    "                #nn.Tanh(),\n",
    "                #nn.Sigmoid(),\n",
    "                #nn.BatchNorm1d(h_n),\n",
    "                Swish(),\n",
    "                nn.Linear(h_n,h_n),\n",
    "                #nn.Tanh(),\n",
    "                #nn.Sigmoid(),\n",
    "                #nn.BatchNorm1d(h_n),\n",
    "                Swish(),\n",
    "                nn.Linear(h_n,h_n),\n",
    "\n",
    "                #nn.BatchNorm1d(h_n),\n",
    "                Swish(),\n",
    "                nn.Linear(h_n,h_n),\n",
    "\n",
    "                #nn.BatchNorm1d(h_n),\n",
    "\n",
    "                Swish(),\n",
    "                nn.Linear(h_n,h_n),\n",
    "\n",
    "                #nn.BatchNorm1d(h_n),\n",
    "\n",
    "                Swish(),\n",
    "                nn.Linear(h_n,h_n),\n",
    "\n",
    "                #nn.BatchNorm1d(h_n),\n",
    "\n",
    "                Swish(),\n",
    "                nn.Linear(h_n,h_n),\n",
    "\n",
    "                #nn.BatchNorm1d(h_n),\n",
    "\n",
    "\n",
    "                Swish(),\n",
    "                nn.Linear(h_n,h_n),\n",
    "\n",
    "                #nn.BatchNorm1d(h_n),\n",
    "\n",
    "\n",
    "                Swish(),\n",
    "\n",
    "                nn.Linear(h_n,1), )\n",
    "        #This function defines the forward rule of\n",
    "        #output respect to input.\n",
    "        #def forward(self,x):\n",
    "        def forward(self,x):\n",
    "            output = self.main(x)\n",
    "            #output_bc = net1_bc_u(x)\n",
    "            #output_dist = net1_dist(x)\n",
    "            if (Flag_BC_exact):\n",
    "                output = output*(x- xStart) *(y- yStart) * (y- yEnd ) + U_BC_in + (y- yStart) * (y- yEnd )  #modify output to satisfy BC automatically \n",
    "            #return  output * (y_in-yStart) * (y_in- yStart_up)\n",
    "            #return output * dist_bc + v_bc\n",
    "            #return output *output_dist * Dist_net_scale + output_bc\n",
    "            return output\n",
    "\n",
    "    class Net2_v(nn.Module):\n",
    "\n",
    "        #The __init__ function stack the layers of the \n",
    "        #network Sequentially \n",
    "        def __init__(self):\n",
    "            super(Net2_v, self).__init__()\n",
    "            self.main = nn.Sequential(\n",
    "                nn.Linear(input_n,h_n),\n",
    "                #nn.Tanh(),\n",
    "                #nn.Sigmoid(),\n",
    "                #nn.BatchNorm1d(h_n),\n",
    "                Swish(),\n",
    "                nn.Linear(h_n,h_n),\n",
    "                #nn.Tanh(),\n",
    "                #nn.Sigmoid(),\n",
    "                #nn.BatchNorm1d(h_n),\n",
    "                Swish(),\n",
    "                nn.Linear(h_n,h_n),\n",
    "\n",
    "                #nn.BatchNorm1d(h_n),\n",
    "                \n",
    "                Swish(),\n",
    "                nn.Linear(h_n,h_n),\n",
    "                #nn.Tanh(),\n",
    "                #nn.Sigmoid(),\n",
    "\n",
    "                #nn.BatchNorm1d(h_n),\n",
    "\n",
    "                Swish(),\n",
    "                nn.Linear(h_n,h_n),\n",
    "\n",
    "                #nn.BatchNorm1d(h_n),\n",
    "\n",
    "                Swish(),\n",
    "                nn.Linear(h_n,h_n),\n",
    "\n",
    "                #nn.BatchNorm1d(h_n),\n",
    "\n",
    "\n",
    "                Swish(),\n",
    "                nn.Linear(h_n,h_n),\n",
    "\n",
    "                #nn.BatchNorm1d(h_n),\n",
    "\n",
    "                Swish(),\n",
    "                nn.Linear(h_n,h_n),\n",
    "\n",
    "                #nn.BatchNorm1d(h_n),\n",
    "\n",
    "                Swish(),\n",
    "                nn.Linear(h_n,h_n),\n",
    "\n",
    "                #nn.BatchNorm1d(h_n),\n",
    "\n",
    "                Swish(),\n",
    "\n",
    "                nn.Linear(h_n,1),)\n",
    "        #This function defines the forward rule of\n",
    "        #output respect to input.\n",
    "        #def forward(self,x):\n",
    "        def forward(self,x):\t\n",
    "            output = self.main(x)\n",
    "            #output_bc = net1_bc_v(x)\n",
    "            #output_dist = net1_dist(x)\n",
    "            if (Flag_BC_exact):\n",
    "                output = output*(x- xStart) *(x- xEnd )*(y- yStart) *(y- yEnd ) + (-0.9*x + 1.) #modify output to satisfy BC automatically \n",
    "            #return  output * (y_in-yStart) * (y_in- yStart_up)\n",
    "            #return output * dist_bc + v_bc\n",
    "            #return output *output_dist * Dist_net_scale + output_bc\n",
    "            return output\n",
    "\n",
    "    class Net2_p(nn.Module):\n",
    "\n",
    "        #The __init__ function stack the layers of the \n",
    "        #network Sequentially \n",
    "        def __init__(self):\n",
    "            super(Net2_p, self).__init__()\n",
    "            self.main = nn.Sequential(\n",
    "                nn.Linear(input_n,h_n),\n",
    "                #nn.Tanh(),\n",
    "                #nn.Sigmoid(),\n",
    "                #nn.BatchNorm1d(h_n),\n",
    "                Swish(),\n",
    "                nn.Linear(h_n,h_n),\n",
    "                #nn.Tanh(),\n",
    "                #nn.Sigmoid(),\n",
    "                #nn.BatchNorm1d(h_n),\n",
    "                Swish(),\n",
    "                nn.Linear(h_n,h_n),\n",
    "                #nn.Tanh(),\n",
    "                #nn.Sigmoid()\n",
    "                \n",
    "                #nn.BatchNorm1d(h_n),\n",
    "\n",
    "                Swish(),\n",
    "                nn.Linear(h_n,h_n),\n",
    "\n",
    "                #nn.BatchNorm1d(h_n),\n",
    "                Swish(),\n",
    "                nn.Linear(h_n,h_n),\n",
    "\n",
    "                #nn.BatchNorm1d(h_n),\n",
    "\n",
    "                Swish(),\n",
    "                nn.Linear(h_n,h_n),\n",
    "\n",
    "                #nn.BatchNorm1d(h_n),\n",
    "\n",
    "                Swish(),\n",
    "                nn.Linear(h_n,h_n),\n",
    "\n",
    "                #nn.BatchNorm1d(h_n),\n",
    "\n",
    "                Swish(),\n",
    "                nn.Linear(h_n,h_n),\n",
    "\n",
    "                #nn.BatchNorm1d(h_n),\n",
    "\n",
    "                Swish(),\n",
    "                nn.Linear(h_n,h_n),\n",
    "\n",
    "                #nn.BatchNorm1d(h_n),\n",
    "\n",
    "                Swish(),\n",
    "                nn.Linear(h_n,h_n),\n",
    "\n",
    "                #nn.BatchNorm1d(h_n),\n",
    "\n",
    "                Swish(),\n",
    "\n",
    "                nn.Linear(h_n,1),)\n",
    "        #This function defines the forward rule of\n",
    "        #output respect to input.\n",
    "        def forward(self,x):\n",
    "            output = self.main(x)\n",
    "            #print('shape of xnet',x.shape) #Resuklts: shape of xnet torch.Size([batchsize, 2]) \n",
    "            if (Flag_BC_exact):\n",
    "                output = output*(x- xStart) *(x- xEnd )*(y- yStart) *(y- yEnd ) + (-0.9*x + 1.) #modify output to satisfy BC automatically \n",
    "            #return  (1-x[:,0]) * output[:,0]  #Enforce P=0 at x=1 #Shape of output torch.Size([batchsize, 1])\n",
    "            return  output\n",
    "\n",
    "################################################################\n",
    "    net2_u = Net2_u().to(device)\n",
    "    net2_v = Net2_v().to(device)\n",
    "    net2_p = Net2_p().to(device)\n",
    "\n",
    "\n",
    "    def init_normal(m):\n",
    "        if type(m) == nn.Linear:\n",
    "            nn.init.kaiming_normal_(m.weight)\n",
    "\n",
    "    # use the modules apply function to recursively apply the initialization\n",
    "    net2_u.apply(init_normal)\n",
    "    net2_v.apply(init_normal)\n",
    "    net2_p.apply(init_normal)\n",
    "\n",
    "\n",
    "    ############################################################################\n",
    "\n",
    "    optimizer_u = optim.Adam(net2_u.parameters(), lr=learning_rate, betas = (0.9,0.99),eps = 10**-15)\n",
    "    optimizer_v = optim.Adam(net2_v.parameters(), lr=learning_rate, betas = (0.9,0.99),eps = 10**-15)\n",
    "    optimizer_p = optim.Adam(net2_p.parameters(), lr=learning_rate, betas = (0.9,0.99),eps = 10**-15)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    def criterion(x,y):\n",
    "\n",
    "        #print (x)\n",
    "        #x = torch.Tensor(x).to(device)\n",
    "        #y = torch.Tensor(y).to(device)\n",
    "        #t = torch.Tensor(t).to(device)\n",
    "        #x = torch.FloatTensor(x).to(device)\n",
    "        #x= torch.from_numpy(x).to(device)\n",
    "\n",
    "        x.requires_grad = True\n",
    "        y.requires_grad = True\n",
    "        #t.requires_grad = True\n",
    "        #u0 = u0.detach()\n",
    "        #v0 = v0.detach()\n",
    "\n",
    "\n",
    "        net_in = torch.cat((x,y),1)\n",
    "        u = net2_u(net_in)\n",
    "        u = u.view(len(u),-1)\n",
    "        v = net2_v(net_in)\n",
    "        v = v.view(len(v),-1)\n",
    "        P = net2_p(net_in)\n",
    "        P = P.view(len(P),-1)\n",
    "        \n",
    "        u_x = torch.autograd.grad(u,x,grad_outputs=torch.ones_like(x),create_graph = True,only_inputs=True)[0]\n",
    "        u_xx = torch.autograd.grad(u_x,x,grad_outputs=torch.ones_like(x),create_graph = True,only_inputs=True)[0]\n",
    "        u_y = torch.autograd.grad(u,y,grad_outputs=torch.ones_like(y),create_graph = True,only_inputs=True)[0]\n",
    "        u_yy = torch.autograd.grad(u_y,y,grad_outputs=torch.ones_like(y),create_graph = True,only_inputs=True)[0]\n",
    "        v_x = torch.autograd.grad(v,x,grad_outputs=torch.ones_like(x),create_graph = True,only_inputs=True)[0]\n",
    "        v_xx = torch.autograd.grad(v_x,x,grad_outputs=torch.ones_like(x),create_graph = True,only_inputs=True)[0]\n",
    "        v_y = torch.autograd.grad(v,y,grad_outputs=torch.ones_like(y),create_graph = True,only_inputs=True)[0]\n",
    "        v_yy = torch.autograd.grad(v_y,y,grad_outputs=torch.ones_like(y),create_graph = True,only_inputs=True)[0]\n",
    "\n",
    "        P_x = torch.autograd.grad(P,x,grad_outputs=torch.ones_like(x),create_graph = True,only_inputs=True)[0]\n",
    "        P_y = torch.autograd.grad(P,y,grad_outputs=torch.ones_like(y),create_graph = True,only_inputs=True)[0]\n",
    "\n",
    "        #u_t = torch.autograd.grad(u,t,grad_outputs=torch.ones_like(t),create_graph = True,only_inputs=True)[0]\n",
    "        #v_t = torch.autograd.grad(v,t,grad_outputs=torch.ones_like(t),create_graph = True,only_inputs=True)[0]\n",
    "        XX_scale = U_scale * (X_scale**2)\n",
    "        YY_scale = U_scale * (Y_scale**2)\n",
    "        UU_scale  = U_scale **2\n",
    "        loss_2 = u*u_x / X_scale + v*u_y / Y_scale - Diff*( u_xx/XX_scale  + u_yy /YY_scale  )+ 1/rho* (P_x / (X_scale*UU_scale)   )  #X-dir\n",
    "        loss_1 = u*v_x / X_scale + v*v_y / Y_scale - Diff*( v_xx/ XX_scale + v_yy / YY_scale )+ 1/rho*(P_y / (Y_scale*UU_scale)   ) #Y-dir\n",
    "        loss_3 = (u_x / X_scale + v_y / Y_scale) #continuity\n",
    "\n",
    "\n",
    "\n",
    "        # MSE LOSS\n",
    "        loss_f = nn.MSELoss()\n",
    "\n",
    "        #Note our target is zero. It is residual so we use zeros_like\n",
    "        loss = loss_f(loss_1,torch.zeros_like(loss_1))+  loss_f(loss_2,torch.zeros_like(loss_2))+  loss_f(loss_3,torch.zeros_like(loss_3))\n",
    "        return loss\n",
    "\n",
    "    def Loss_BC(xb,yb,ub,vb, xb_inlet, yb_inlet, ub_inlet, x, y ):\n",
    "\n",
    "        net_in1 = torch.cat((xb, yb), 1)\n",
    "        out1_u = net2_u(net_in1)\n",
    "        out1_v = net2_v(net_in1)\n",
    "        out1_u = out1_u.view(len(out1_u), -1)\n",
    "        out1_v = out1_v.view(len(out1_v), -1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        loss_f = nn.MSELoss()\n",
    "        loss_noslip = loss_f(out1_u, torch.zeros_like(out1_u)) + loss_f(out1_v, torch.zeros_like(out1_v)) \n",
    "        #loss_inlet = loss_f(out2_u, ub_inlet) + loss_f(out2_v, torch.zeros_like(out2_v) )\n",
    "\n",
    "        return loss_noslip\n",
    "\n",
    "\n",
    "    def Loss_data(xd,yd,ud,vd ):\n",
    "\n",
    "        #xb.requires_grad = True\n",
    "        #xd.requires_grad = True\n",
    "        #yd.requires_grad = True\n",
    "        \n",
    "        net_in1 = torch.cat((xd, yd), 1)\n",
    "        out1_u = net2_u(net_in1)\n",
    "        out1_v = net2_v(net_in1)\n",
    "        \n",
    "        out1_u = out1_u.view(len(out1_u), -1)\n",
    "        out1_v = out1_v.view(len(out1_v), -1)\n",
    "\n",
    "\n",
    "        loss_f = nn.MSELoss()\n",
    "        loss_d = loss_f(out1_u, ud) + loss_f(out1_v, vd) \n",
    "\n",
    "\n",
    "        return loss_d\n",
    "\n",
    "    # Main loop\n",
    "\n",
    "    tic = time.time()\n",
    "\n",
    "\n",
    "    if(Flag_pretrain):\n",
    "        print('Reading (pretrain) functions first...')\n",
    "        net2_u.load_state_dict(torch.load(path+\"sten_u\" + \".pt\"))\n",
    "        net2_v.load_state_dict(torch.load(path+\"sten_v\" + \".pt\"))\n",
    "        net2_p.load_state_dict(torch.load(path+\"sten_p\" + \".pt\"))\n",
    "        \n",
    "\n",
    "    if (Flag_schedule):\n",
    "        scheduler_u = torch.optim.lr_scheduler.StepLR(optimizer_u, step_size=step_epoch, gamma=decay_rate)\n",
    "        scheduler_v = torch.optim.lr_scheduler.StepLR(optimizer_v, step_size=step_epoch, gamma=decay_rate)\n",
    "        scheduler_p = torch.optim.lr_scheduler.StepLR(optimizer_p, step_size=step_epoch, gamma=decay_rate)\n",
    "\n",
    "    if(Flag_batch):# This one uses dataloader\n",
    "            \n",
    "            for epoch in range(epochs):\n",
    "                #for batch_idx, (x_in,y_in) in enumerate(dataloader):  \n",
    "                #for batch_idx, (x_in,y_in,xb_in,yb_in,ub_in,vb_in) in enumerate(dataloader): \n",
    "                loss_eqn_tot = 0.\n",
    "                loss_bc_tot = 0.\n",
    "                loss_data_tot = 0.\n",
    "                n = 0\n",
    "                for batch_idx, (x_in,y_in) in enumerate(dataloader): \n",
    "                    #net_in = torch.cat((x_in,y_in),1)\n",
    "                    #u_bc = net1_bc_u(net_in)\n",
    "                    #v_bc = net1_bc_v(net_in)\n",
    "                    #dist_bc = net1_dist(net_in)\n",
    "\n",
    "                    #net2_psi.zero_grad()\n",
    "                    net2_u.zero_grad()\n",
    "                    net2_v.zero_grad()\n",
    "                    net2_p.zero_grad()\n",
    "                    loss_eqn = criterion(x_in,y_in)\n",
    "                    loss_bc = Loss_BC(xb,yb,ub,vb,xb_inlet,yb_inlet,ub_inlet,x,y)\n",
    "                    loss_data = Loss_data(xd,yd,ud,vd)\n",
    "                    loss = loss_eqn + Lambda_BC* loss_bc + Lambda_data*loss_data\n",
    "                    loss.backward()\n",
    "                    optimizer_u.step() \n",
    "                    optimizer_v.step()\n",
    "                    #optimizer_psi.step()  \n",
    "                    optimizer_p.step()  \n",
    "                    loss_eqn_tot += loss_eqn\n",
    "                    loss_bc_tot += loss_bc\n",
    "                    loss_data_tot  += loss_data\n",
    "                    n += 1 \n",
    "                    if batch_idx % 40 ==0:\n",
    "                        #loss_bc = Loss_BC(xb,yb,ub,vb) #causes out of memory issue for large data in cuda\n",
    "                        print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss eqn {:.10f} Loss BC {:.8f} Loss data {:.8f}'.format(\n",
    "                            epoch, batch_idx * len(x_in), len(dataloader.dataset),\n",
    "                            100. * batch_idx / len(dataloader), loss_eqn.item(), loss_bc.item(),loss_data.item()))\n",
    "                        #print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss eqn {:.10f} '.format(\n",
    "                        #epoch, batch_idx * len(x_in), len(dataloader.dataset),\n",
    "                        #100. * batch_idx / len(dataloader), loss.item()))\n",
    "                if (Flag_schedule):\n",
    "                        scheduler_u.step()\n",
    "                        scheduler_v.step()\n",
    "                        scheduler_p.step()\n",
    "                loss_eqn_tot = loss_eqn_tot / n\n",
    "                loss_bc_tot = loss_bc_tot / n\n",
    "                loss_data_tot = loss_data_tot / n\n",
    "                print('*****Total avg Loss : Loss eqn {:.10f} Loss BC {:.10f} Loss data {:.10f} ****'.format(loss_eqn_tot, loss_bc_tot,loss_data_tot) )\n",
    "                print('learning rate is ', optimizer_u.param_groups[0]['lr'], optimizer_v.param_groups[0]['lr'])\n",
    "            if(0): #This causes out of memory in cuda in autodiff\n",
    "                loss_eqn = criterion(x,y)\t\n",
    "                loss_bc = Loss_BC(xb,yb,ub,vb)\n",
    "                loss = loss_eqn #+ Lambda_BC* loss_bc\n",
    "                print('**** Final (all batches) \\tLoss: {:.10f} \\t Loss BC {:.6f}'.format(\n",
    "                    loss.item(),loss_bc.item()))\n",
    "\n",
    "    else:\n",
    "        for epoch in range(epochs):\n",
    "            #zero gradient\n",
    "            #net1.zero_grad()\n",
    "            ##Closure function for LBFGS loop:\n",
    "            #def closure():\n",
    "            net2.zero_grad()\n",
    "            loss_eqn = criterion(x,y)\n",
    "            loss_bc = Loss_BC(xb,yb,cb)\n",
    "            if (Flag_BC_exact):\n",
    "                loss = loss_eqn #+ loss_bc\n",
    "            else:\n",
    "                loss = loss_eqn + Lambda_BC * loss_bc\n",
    "            loss.backward()\n",
    "            #return loss\n",
    "            #loss = closure()\n",
    "            #optimizer2.step(closure)\n",
    "            #optimizer3.step(closure)\n",
    "            #optimizer4.step(closure)\n",
    "            optimizer_u.step() \n",
    "            optimizer_v.step() \n",
    "            optimizer_p.step() \n",
    "            if epoch % 10 ==0:\n",
    "                print('Train Epoch: {} \\tLoss: {:.10f} \\t Loss BC {:.6f}'.format(\n",
    "                    epoch, loss.item(),loss_bc.item()))\n",
    "\n",
    "    toc = time.time()\n",
    "    elapseTime = toc - tic\n",
    "    print (\"elapse time in parallel = \", elapseTime)\n",
    "    ###################\n",
    "    #plot\n",
    "    if (1):#save network\n",
    "        torch.save(net2_p.state_dict(),path+\"IA_data_p\" + \".pt\")\n",
    "        torch.save(net2_u.state_dict(),path+\"IA_data_u\" + \".pt\")\n",
    "        torch.save(net2_v.state_dict(),path+\"IA_data_v\" + \".pt\")\n",
    "        print (\"Data saved!\")\n",
    "\n",
    "\n",
    "\n",
    "    net_in = torch.cat((x.requires_grad_(),y.requires_grad_()),1)\n",
    "    output_u = net2_u(net_in)  #evaluate model (runs out of memory for large GPU problems!)\n",
    "    output_v = net2_v(net_in)  #evaluate model\n",
    "\n",
    "    output_u = output_u.cpu().data.numpy() #need to convert to cpu before converting to numpy\n",
    "    output_v = output_v.cpu().data.numpy()\n",
    "    x = x.cpu()\n",
    "    y = y.cpu()\n",
    "\n",
    "    plt.figure()\n",
    "    plt.subplot(2, 1, 1)\n",
    "    plt.scatter(x.detach().numpy(), y.detach().numpy(), c = output_u , cmap = 'rainbow')\n",
    "    plt.title('NN results, u')\n",
    "    plt.colorbar()\n",
    "    plt.show()\n",
    "    plt.figure()\n",
    "    plt.subplot(2, 1, 1)\n",
    "    plt.scatter(x.detach().numpy(), y.detach().numpy(), c = output_v , cmap = 'rainbow')\n",
    "    plt.title('NN results, v')\n",
    "    plt.colorbar()\n",
    "    plt.show()\n",
    "    \n",
    "    return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "533c7bec-c71e-46dc-8368-1b5a9cc9c1b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cpu\") #Can change to 'cpu'\n",
    "\n",
    "Flag_batch = True #False #USe batch or not  #With batch getting error...\n",
    "Flag_BC_exact = False #If True enforces BC exactly HELPS ALOT!!! Not implemented in 2D\n",
    "Lambda_BC  = 1. \n",
    "Lambda_data = 1.\n",
    "\n",
    "# Directory = \"PINN-wss/\" #Change as needed, copy the path of the directory you want to save data into here\n",
    "# mesh_file = Directory + \"IA_mesh_correct_crop.vtu\" # name of file to save the mesh to\n",
    "# bc_file_in = Directory + \"inlet_BC_crop_correct.vtk\" # name of file to save the bc in\n",
    "# bc_file_wall = Directory + \"wall_BC_crop_correct.vtk\" # name of file for the wall bc\n",
    "\n",
    "mesh_file = \"IA_mesh_correct_crop.vtu\" # name of file to save the mesh to\n",
    "bc_file_in = \"inlet_BC_crop_correct.vtk\" # name of file to save the bc in\n",
    "bc_file_wall = \"wall_BC_crop_correct.vtk\" # name of file for the wall bc\n",
    "\n",
    "File_data = \"velocity_IA_steady.vtu\"\n",
    "fieldname = 'f_5-0' #The velocity field name in the vtk file (see from ParaView)\n",
    "\n",
    "Flag_pretrain = False # True #If true reads the nets from last run"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bd9acc4-82bc-4d1d-b491-97415327a48e",
   "metadata": {},
   "source": [
    "### Immediately below are the parameters you can change"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d4820f54-5348-4558-a47d-b8fc3fefefea",
   "metadata": {},
   "outputs": [],
   "source": [
    "batchsize = 256  \n",
    "learning_rate = 1e-5 \n",
    "epochs  = 5500 \n",
    "Diff = 0.00125 #Such that Re = 320\n",
    "rho = 1.\n",
    "T = 0.5 #total duration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4839eaa8-5ad8-4275-bb7a-a1dc7d0d59aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "Flag_x_length = True #if True scales the eqn such that the length of the domain is = X_scale\n",
    "X_scale = 3.0 #The length of the  domain (need longer length for separation region)\n",
    "Y_scale = 2.0 \n",
    "U_scale = 1.0\n",
    "U_BC_in = 0.5\n",
    "\n",
    "\n",
    "Lambda_div = 1.  #penalty factor for continuity eqn \n",
    "Lambda_v = 1. #penalty factor for y-momentum equation\n",
    "\n",
    "#https://stackoverflow.com/questions/60050586/pytorch-change-the-learning-rate-based-on-number-of-epochs\n",
    "Flag_schedule = True #If true change the learning rate \n",
    "if (Flag_schedule):\n",
    "    learning_rate = 5e-4 #starting learning rate\n",
    "    step_epoch = 1200 \n",
    "    decay_rate = 0.1 \n",
    "\n",
    "\n",
    "if (not Flag_x_length):\n",
    "    X_scale = 1.\n",
    "    Y_scale = 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b7077501-8606-4b04-b2db-8e8822971c2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading IA_mesh_correct_crop.vtu\n",
      "n_points of the mesh: 18702\n",
      "shape of x (18702, 1)\n",
      "shape of y (18702, 1)\n",
      "Loading inlet_BC_crop_correct.vtk\n",
      "n_points of at inlet 109\n",
      "Loading wall_BC_crop_correct.vtk\n",
      "n_points of at wall 445\n"
     ]
    }
   ],
   "source": [
    "print ('Loading', mesh_file)\n",
    "reader = vtk.vtkXMLUnstructuredGridReader()\n",
    "reader.SetFileName(mesh_file)\n",
    "reader.Update()\n",
    "data_vtk = reader.GetOutput()\n",
    "n_points = data_vtk.GetNumberOfPoints()\n",
    "print ('n_points of the mesh:' ,n_points)\n",
    "x_vtk_mesh = np.zeros((n_points,1))\n",
    "y_vtk_mesh = np.zeros((n_points,1))\n",
    "VTKpoints = vtk.vtkPoints()\n",
    "for i in range(n_points):\n",
    "    pt_iso  =  data_vtk.GetPoint(i)\n",
    "    x_vtk_mesh[i] = pt_iso[0]\n",
    "    y_vtk_mesh[i] = pt_iso[1]\n",
    "    VTKpoints.InsertPoint(i, pt_iso[0], pt_iso[1], pt_iso[2])\n",
    "\n",
    "point_data = vtk.vtkUnstructuredGrid()\n",
    "point_data.SetPoints(VTKpoints)\n",
    "\n",
    "x  = np.reshape(x_vtk_mesh , (np.size(x_vtk_mesh [:]),1)) \n",
    "y  = np.reshape(y_vtk_mesh , (np.size(y_vtk_mesh [:]),1))\n",
    "nPt = 130  \n",
    "xStart = 0.\n",
    "xEnd = 1.\n",
    "yStart = 0.\n",
    "yEnd = 1.0\n",
    "delta_circ = 0.2\n",
    "\n",
    "t = np.linspace(0., T, nPt*nPt)\n",
    "t=t.reshape(-1, 1)\n",
    "print('shape of x',x.shape)\n",
    "print('shape of y',y.shape)\n",
    "#print('shape of t',t.shape)\n",
    "\n",
    "## Define boundary points\n",
    "print ('Loading', bc_file_in)\n",
    "reader = vtk.vtkUnstructuredGridReader()\n",
    "reader.SetFileName(bc_file_in)\n",
    "reader.Update()\n",
    "data_vtk = reader.GetOutput()\n",
    "n_points = data_vtk.GetNumberOfPoints()\n",
    "print ('n_points of at inlet' ,n_points)\n",
    "x_vtk_mesh = np.zeros((n_points,1))\n",
    "y_vtk_mesh = np.zeros((n_points,1))\n",
    "VTKpoints = vtk.vtkPoints()\n",
    "for i in range(n_points):\n",
    "\tpt_iso  =  data_vtk.GetPoint(i)\n",
    "\tx_vtk_mesh[i] = pt_iso[0]\t\n",
    "\ty_vtk_mesh[i] = pt_iso[1]\n",
    "\tVTKpoints.InsertPoint(i, pt_iso[0], pt_iso[1], pt_iso[2])\n",
    "point_data = vtk.vtkUnstructuredGrid()\n",
    "point_data.SetPoints(VTKpoints)\n",
    "xb_in  = np.reshape(x_vtk_mesh , (np.size(x_vtk_mesh[:]),1)) \n",
    "yb_in  = np.reshape(y_vtk_mesh , (np.size(y_vtk_mesh[:]),1))\n",
    "\n",
    "print ('Loading', bc_file_wall)\n",
    "reader = vtk.vtkUnstructuredGridReader()\n",
    "reader.SetFileName(bc_file_wall)\n",
    "reader.Update()\n",
    "data_vtk = reader.GetOutput()\n",
    "n_pointsw = data_vtk.GetNumberOfPoints()\n",
    "print ('n_points of at wall' ,n_pointsw)\n",
    "x_vtk_mesh = np.zeros((n_pointsw,1))\n",
    "y_vtk_mesh = np.zeros((n_pointsw,1))\n",
    "VTKpoints = vtk.vtkPoints()\n",
    "for i in range(n_pointsw):\n",
    "    pt_iso  =  data_vtk.GetPoint(i)\n",
    "    x_vtk_mesh[i] = pt_iso[0]\t\n",
    "    y_vtk_mesh[i] = pt_iso[1]\n",
    "    VTKpoints.InsertPoint(i, pt_iso[0], pt_iso[1], pt_iso[2])\n",
    "point_data = vtk.vtkUnstructuredGrid()\n",
    "point_data.SetPoints(VTKpoints)\n",
    "xb_wall  = np.reshape(x_vtk_mesh , (np.size(x_vtk_mesh [:]),1)) \n",
    "yb_wall  = np.reshape(y_vtk_mesh , (np.size(y_vtk_mesh [:]),1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2b1f9c7-d87f-4d1c-80aa-d90194b6eed2",
   "metadata": {},
   "source": [
    "### In the cell below you can experiment with different BC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e5a52bfb-7080-4d1f-8d40-ac66a1b501bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of xb (445, 1)\n",
      "shape of yb (445, 1)\n",
      "shape of ub (445, 1)\n"
     ]
    }
   ],
   "source": [
    "#u_in_BC = np.linspace(U_BC_in, U_BC_in, n_points) #constant uniform BC\n",
    "u_in_BC = (yb_in[:]) * ( 0.2 - yb_in[:] )  / 0.01 * U_BC_in #parabolic\n",
    "\n",
    "\n",
    "v_in_BC = np.linspace(0., 0., n_points)\n",
    "u_wall_BC = np.linspace(0., 0., n_pointsw)\n",
    "v_wall_BC = np.linspace(0., 0., n_pointsw)\n",
    "#t_BC = np.linspace(0., T, nPt_BC)\n",
    "#t_BC = np.linspace(0., T, nPt_time)\n",
    "\n",
    "#t_BC = np.linspace(0., T, nPt_BC)\n",
    "#t_BC = np.linspace(0., T, nPt_time)\n",
    "\n",
    "#tb = np.concatenate((t_BC, t_BC, t_BC), 0)\n",
    "#xb = np.concatenate((xb_wall), 0)\n",
    "#yb = np.concatenate((yb_wall), 0)\n",
    "xb = xb_wall\n",
    "yb = yb_wall\n",
    "\n",
    "#ub = np.concatenate((u_wall_BC), 0)\n",
    "#vb = np.concatenate((v_wall_BC), 0)\n",
    "ub = u_wall_BC\n",
    "vb = v_wall_BC\n",
    "\n",
    "#xb_inlet = np.concatenate((xb_in), 0)\n",
    "#yb_inlet = np.concatenate((yb_in), 0)\n",
    "#ub_inlet = np.concatenate((u_in_BC), 0)\n",
    "#vb_inlet = np.concatenate((v_in_BC), 0)\n",
    "\n",
    "xb_inlet = xb_in \n",
    "yb_inlet =yb_in \n",
    "\n",
    "\n",
    "ub_inlet = u_in_BC\n",
    "vb_inlet = v_in_BC\n",
    "\n",
    "\n",
    "### Trying to set distance function with Dirichlet BC everywhere\n",
    "#xb_dist = np.concatenate((xleft, xup,xrightw, xdown,xdown2,xright), 0)\n",
    "#yb_dist = np.concatenate((yleft, yup,yrightw, ydown,ydown2,yright), 0)\n",
    "####\n",
    "\n",
    "\n",
    "#tb= tb.reshape(-1, 1) #need to reshape to get 2D array\n",
    "xb= xb.reshape(-1, 1) #need to reshape to get 2D array\n",
    "yb= yb.reshape(-1, 1) #need to reshape to get 2D array\n",
    "ub= ub.reshape(-1, 1) #need to reshape to get 2D array\n",
    "vb= vb.reshape(-1, 1) #need to reshape to get 2D array\n",
    "xb_inlet= xb_inlet.reshape(-1, 1) #need to reshape to get 2D array\n",
    "yb_inlet= yb_inlet.reshape(-1, 1) #need to reshape to get 2D array\n",
    "ub_inlet= ub_inlet.reshape(-1, 1) #need to reshape to get 2D array\n",
    "vb_inlet= vb_inlet.reshape(-1, 1) #need to reshape to get 2D array\n",
    "\n",
    "print('shape of xb',xb.shape)\n",
    "print('shape of yb',yb.shape)\n",
    "print('shape of ub',ub.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7728c724-1dc0-4f3e-836f-604e2b99cf8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading velocity_IA_steady.vtu\n",
      "n_points of the data file read: 31026\n",
      "Using input data pts: pts:  [0.6        0.66666667 0.5        0.58333333 0.7       ] [0.2   0.25  0.1   0.45  0.375]\n",
      "Using input data pts: vel u:  [ 0.25904188  0.09671328  0.9822161  -0.07069281 -0.05356446]\n",
      "Using input data pts: vel v:  [-0.00256067  0.00326983  0.01271351 -0.03981408  0.09698547]\n",
      "Train Epoch: 0 [0/18702 (0%)]\tLoss eqn 0.0006850413 Loss BC 0.00139982 Loss data 0.20325127\n"
     ]
    }
   ],
   "source": [
    "##### Read data here#########\n",
    "\n",
    "#!!specify pts location here:\n",
    "x_data = [1.8, 2.0, 1.5, 1.75, 2.1 ] \n",
    "y_data =[0.4, 0.5, 0.2, 0.9, 0.75 ]\n",
    "z_data  = [0.,0.,0.,0.,0. ]\n",
    "\n",
    "\n",
    "x_data = np.asarray(x_data)  #convert to numpy \n",
    "y_data = np.asarray(y_data) #convert to numpy \n",
    "\n",
    "\n",
    "print ('Loading', File_data)\n",
    "reader = vtk.vtkXMLUnstructuredGridReader()\n",
    "reader.SetFileName(File_data)\n",
    "reader.Update()\n",
    "data_vtk = reader.GetOutput()\n",
    "n_points = data_vtk.GetNumberOfPoints()\n",
    "print ('n_points of the data file read:' ,n_points)\n",
    "\n",
    "\n",
    "VTKpoints = vtk.vtkPoints()\n",
    "for i in range(len(x_data)): \n",
    "    VTKpoints.InsertPoint(i, x_data[i] , y_data[i]  , z_data[i])\n",
    "\n",
    "point_data = vtk.vtkUnstructuredGrid()\n",
    "point_data.SetPoints(VTKpoints)\n",
    "\n",
    "probe = vtk.vtkProbeFilter()\n",
    "probe.SetInputData(point_data)\n",
    "probe.SetSourceData(data_vtk)\n",
    "probe.Update()\n",
    "array = probe.GetOutput().GetPointData().GetArray(fieldname)\n",
    "data_vel = VN.vtk_to_numpy(array)\n",
    "\n",
    "\n",
    "\n",
    "data_vel_u = data_vel[:,0] / U_scale\n",
    "data_vel_v = data_vel[:,1] / U_scale\n",
    "x_data = x_data / X_scale\n",
    "y_data = y_data / Y_scale\n",
    "\n",
    "print('Using input data pts: pts: ',x_data, y_data)\n",
    "print('Using input data pts: vel u: ',data_vel_u)\n",
    "print('Using input data pts: vel v: ',data_vel_v)\n",
    "xd= x_data.reshape(-1, 1) #need to reshape to get 2D array\n",
    "yd= y_data.reshape(-1, 1) #need to reshape to get 2D array\n",
    "ud= data_vel_u.reshape(-1, 1) #need to reshape to get 2D array\n",
    "vd= data_vel_v.reshape(-1, 1) #need to reshape to get 2D array\n",
    "\n",
    "\n",
    "path = \"aneurysmsigma01scalepara_100pt-tmp_\"\n",
    "geo_train(device,x,y,xb,yb,ub,vb,xd,yd,ud,vd,batchsize,learning_rate,epochs,path,Flag_batch,Diff,rho,Flag_BC_exact,Lambda_BC,nPt,T,xb_inlet,yb_inlet,ub_inlet,vb_inlet )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bd25f1e-9ff1-4d68-a311-a9816710baa6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
